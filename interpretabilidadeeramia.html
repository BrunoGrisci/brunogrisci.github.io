<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interpretação de Modelos de Aprendizado de Máquina - I ERAMIA-RS</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #ffffff;
            color: #333;
            line-height: 1.6;
            margin: 0;
            padding: 40px;
        }
        h1, h2, h3 {
            color: #005A9C;
        }
        h1 {
            border-bottom: 3px solid #005A9C;
            padding-bottom: 10px;
        }
        h2 {
            margin-top: 40px;
        }
        ul {
            margin-left: 20px;
        }
        .container {
            max-width: 900px;
            margin: auto;
        }
        .footer {
            margin-top: 50px;
            font-style: italic;
            color: #555;
        }
        .contact a { color: #005A9C; text-decoration: none; }
        .contact a:hover { text-decoration: underline; }
        .tag {
            display: inline-block;
            background: #E6F0FA;
            color: #005A9C;
            padding: 2px 8px;
            border-radius: 999px;
            font-size: 0.9rem;
            margin-left: 8px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Interpretação de Modelos de Aprendizado de Máquina</h1>
        <h2>I ERAMIA‑RS</h2>
        <h3>Prof. Bruno Iochins Grisci</h3>
        <div class="contact">
            E‑mail: <a href="mailto:bigrisci@inf.ufrgs.br">bigrisci@inf.ufrgs.br</a><br>
            Site: <a href="https://brunogrisci.github.io/" target="_blank" rel="noopener">https://brunogrisci.github.io/</a>
        </div>

        <h3>MSc. Débora Cristina Santos de Sousa</h3>
        <div class="contact">
            E‑mail: <a href="mailto:debora.sousa@inf.ufrgs.br">debora.sousa@inf.ufrgs.br</a><br>
            Site: <a href="http://lattes.cnpq.br/9112276170232610" target="_blank" rel="noopener">http://lattes.cnpq.br/9112276170232610</a>
        </div>

        <h2>Descrição</h2>
        <p><strong>[Minicurso 7] Interpretação de Modelos de Aprendizado de Máquina</strong></p>
        <p>O minicurso apresenta os fundamentos da interpretação de modelos de aprendizado de máquina, abordando tanto modelos naturalmente interpretáveis quanto técnicas modernas de explicação aplicáveis a modelos complexos. Serão discutidos métodos globais e locais, além de reflexões críticas sobre limitações e boas práticas no uso dessas ferramentas.</p>
        <p>Na parte prática, será realizada uma atividade em Python (Jupyter Notebook) com foco em modelos de árvore, abrangendo desde a preparação dos dados até a interpretação dos resultados. Os participantes aprenderão a manipular conjuntos de dados tabulares, explorar a influência de diferentes parâmetros no desempenho do modelo, extrair a relevância de características em estudo e visualizar os resultados por meio de gráficos, proporcionando uma compreensão prática de como construir, avaliar e interpretar modelos de árvore para análise de dados.</p>
        <p><strong>Formato:</strong> Teórico (1h30) e Prático (1h30)<br>
        <strong>Pré‑requisitos:</strong> Para a parte teórica, noções básicas de aprendizado de máquina são desejáveis. Para a parte prática, recomenda‑se conhecimento básico de Python.<br>
        <strong>Horário e Local:</strong> 12/11 (8:30 – 10:00) — Auditório Inferior / Prédio 43413; 12/11 (10:30 – 12:00) — LAB 102 / Prédio 43413<br>
        <strong>Vagas:</strong> 40 vagas curso teórico + prático; 40 vagas apenas para parte teórica</p>

        <h2>Informações do Evento</h2>
        <p><strong>I ERAMIA‑RS — Escola Regional de Aprendizado de Máquina e IA do Rio Grande do Sul</strong><br>
        12 – 14 de novembro de 2025<br>
        Site oficial: <a href="https://eramia-rs.sbc.org.br/#/" target="_blank" rel="noopener">https://eramia-rs.sbc.org.br</a></p>

        <h2>Materiais do Curso</h2>
        <ul>
            <li><a href="https://www.youtube.com/watch?v=QZdf6X4u5mU" target="_blank">Gravação: https://www.youtube.com/watch?v=QZdf6X4u5mU</a></li>
            <li><a href="https://brunogrisci.github.io/eramiaslides/interpretabilidade_brunogrisci.pdf" target="_blank">Slides (PDF): https://brunogrisci.github.io/eramiaslides/interpretabilidade_brunogrisci.pdf</a></li>
        </ul>

        <h2>Projeto</h2>
        <p>Notebook / atividade prática: <a href="https://colab.research.google.com/drive/1zCMYU13jNi98KaPQJoL6py_NymZiC3I0#scrollTo=0jOO48Rl-yA4" target="_blank" rel="noopener">https://colab.research.google.com/drive/1zCMYU13jNi98KaPQJoL6py_NymZiC3I0#scrollTo=0jOO48Rl-yA4</a></p>

        <h2>Bibliografia</h2>
        <ul>
            <li>Al‑Zawi, S. A. T. A. M. S.; Mohammed, T.; Albawi, S. (2017). "Understanding of a convolutional neural network." In: <em>ICET 2017</em>, pp. 1–6.</li>            
            <li>Aurélien Géron (2019). <em>Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. 2ª edição.</li>
            <li>Bach, S. et al. (2015). "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation." <em>PLOS ONE</em>, 10(7), e0130140.</li>
            <li>Barbieri, M. C.; Grisci, B. I.; Dorn, M. (2024). "Analysis and comparison of feature selection methods towards performance and stability." <em>Expert Systems with Applications</em>, 249, 123667.</li>
            <li>Buhrmester, V.; Münch, D.; Arens, M. (2021). "Analysis of explainers of black box deep neural networks for computer vision: A survey." <em>Machine Learning and Knowledge Extraction</em>, 3(4), 966–989.</li>
            <li>Cooney, A.; Nanda, N. (2023). <em>Circuitsvis</em>.</li>
            <li>DeLMA; Cukierski, W. (2013). <em>The ICML 2013 Whale Challenge - Right Whale Redux</em>. Kaggle. Acessado em 09/03/2025.</li>
            <li>Domingos, P. (2012). "A few useful things to know about machine learning." <em>Communications of the ACM</em>, 55(10), 78–87.</li>
            <li>Elhage, N. et al. (2021). "A mathematical framework for transformer circuits." <em>Transformer Circuits Thread</em>, 1(1), 12.</li>
            <li>Geirhos, R. et al. (2020). "Shortcut learning in deep neural networks." <em>Nature Machine Intelligence</em>, 2(11), 665–673.</li>
            <li>Gurnee, W. et al. (2024). "Universal neurons in GPT‑2 language models." <em>arXiv preprint</em> arXiv:2401.12181.</li>
            <li>Grisci, B. I.; Inostroza-Ponta, M.; Dorn, M. (2025). "Assessing feature scorer results on high-dimensional datasets with t-SNE." <em>Neurocomputing</em>, p. 130561.</li>
            <li>Kumar, A. et al. (2025). "Questioning Representational Optimism in Deep Learning: The Fractured Entangled Representation Hypothesis." <em>arXiv preprint</em> arXiv:2505.11581.</li> 
            <li>Lapuschkin, S. et al. (2019). "Unmasking Clever Hans predictors and assessing what machines really learn." <em>Nature Communications</em>, 10, 1096.</li>
            <li>Lindsey, J. et al. (2025). <em>On the Biology of a Large Language Model</em>. Acessado em 11/11/2025. Disponível em: https://transformer-circuits.pub/2025/attribution-graphs/biology.html.</li>           
            <li>Miller, T. (2019). "Explanation in artificial intelligence: Insights from the social sciences." <em>Artificial Intelligence</em>, 267, 1–38.</li>
            <li>Molnar, C. (2020). <em>Interpretable Machine Learning</em>. Lulu.com.</li>
            <li>Molnar, C. (2025). <em>Points, Rules, Weights, Distributions: The Elements of Machine Learning</em>. Acessado em 09/11/2025.</li>
            <li>Montavon, G.; Samek, W.; Müller, K.-R. (2018). "Methods for interpreting and understanding deep neural networks." <em>Digital Signal Processing</em>, 73, 1–15.</li>
            <li>Murdoch, W. J. et al. (2019). "Definitions, methods, and applications in interpretable machine learning." <em>PNAS</em>, 116(44), 22071–22080.</li>
            <li>Olah, C.; Cammarata, N. et al. (2020). "Zoom In: An introduction to circuits." <em>Distill</em>, 5(3), e00024–001.</li>
            <li>Olah, C.; Mordvintsev, A.; Schubert, L. (2017). "Feature visualization." <em>Distill</em>, 2(11), e7.</li>
            <li>Prince, S. J. D. (2023). <em>Understanding Deep Learning</em>. MIT Press.</li>
            <li>Rai, D. et al. (2024). "A practical review of mechanistic interpretability for transformer-based language models." <em>arXiv preprint</em> arXiv:2407.02646.</li>
            <li>Ribeiro, M. T.; Singh, S.; Guestrin, C. (2016a). "Why should I trust you?" In: <em>Proc. SIGKDD</em>, pp. 1135–1144.</li>
            <li>Ribeiro, M. T.; Singh, S.; Guestrin, C. (2016b). "Model-agnostic interpretability of machine learning." <em>arXiv preprint</em> arXiv:1606.05386.</li>
            <li>Roscher, R. et al. (2020). "Explainable machine learning for scientific insights and discoveries." <em>IEEE Access</em>, 8, 42200–42216.</li>
            <li>Rudin, C. (2019). "Stop explaining black box machine learning models..." <em>Nature Machine Intelligence</em>, 1(5), 206–215.</li>
            <li>Scholbeck, C. A. et al. (2019). "Sampling, intervention, prediction, aggregation..." In: <em>ECML PKDD</em>. Springer, 205–216.</li>
            <li>Szegedy, C. et al. (2013). "Intriguing properties of neural networks." <em>arXiv preprint</em> arXiv:1312.6199.</li>
        </ul>

        <div class="footer">
            <p>I ERAMIA‑RS | Interpretação de Modelos de AM | Prof. Bruno Iochins Grisci &amp; MSc. Débora Cristina Santos de Sousa</p>
        </div>
    </div>
</body>
</html>
